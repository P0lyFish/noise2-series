{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"noise2self.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP9DA88uIXwV7bM9CT8JUg4"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R8d4E769lHhU","executionInfo":{"status":"ok","timestamp":1609862979381,"user_tz":-420,"elapsed":66235,"user":{"displayName":"Trần Thế Phong","photoUrl":"","userId":"01470146533676069687"}},"outputId":"bd83ebc0-9d03-4696-ee26-e88e63852237"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","%cd \"/content/gdrive/My Drive/vinAI/noise2self/noise2self\"\n","!ls"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n","/content/gdrive/My Drive/vinAI/noise2self/noise2self\n","data\t\t mask.py\t\toptions\t\t   train.py\n","environment.yml  metrics_evaluation.py\tpretrained_models  train.sh\n","figs\t\t models\t\t\t__pycache__\t   utils\n","index.html\t noise2self.ipynb\tREADME.md\n","LICENSE\t\t notebooks\t\ttest.sh\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"57_0GYBJddwu","executionInfo":{"status":"ok","timestamp":1609863733358,"user_tz":-420,"elapsed":1924,"user":{"displayName":"Trần Thế Phong","photoUrl":"","userId":"01470146533676069687"}},"outputId":"ffdbd401-93dc-46ba-8337-e9ca0bac17c7"},"source":["# !git init\n","# !git add .\n","# !git commit -m \"first commit\"\n","# !git push origin main\n","!git config --global user.email \"tranthephong32@gmail.com\"\n","!git config --global user.name \"P0lyFish\"\n","!git add .\n","!git commit -m \"fix bugs in masking\"\n","!git push origin main\n","!git status"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Fetching origin\n","remote: Enumerating objects: 9, done.\u001b[K\n","remote: Counting objects:  11% (1/9)\u001b[K\rremote: Counting objects:  22% (2/9)\u001b[K\rremote: Counting objects:  33% (3/9)\u001b[K\rremote: Counting objects:  44% (4/9)\u001b[K\rremote: Counting objects:  55% (5/9)\u001b[K\rremote: Counting objects:  66% (6/9)\u001b[K\rremote: Counting objects:  77% (7/9)\u001b[K\rremote: Counting objects:  88% (8/9)\u001b[K\rremote: Counting objects: 100% (9/9)\u001b[K\rremote: Counting objects: 100% (9/9), done.\u001b[K\n","remote: Compressing objects: 100% (1/1)\u001b[K\rremote: Compressing objects: 100% (1/1), done.\u001b[K\n","remote: Total 5 (delta 4), reused 5 (delta 4), pack-reused 0\u001b[K\n","Unpacking objects: 100% (5/5), done.\n","From https://github.com/P0lyFish/noise2self\n","   5d3ed5f..29e5e63  main       -> origin/main\n","HEAD is now at 29e5e63 fix bug in maskers\n","On branch main\n","Changes not staged for commit:\n","  (use \"git add <file>...\" to update what will be committed)\n","  (use \"git checkout -- <file>...\" to discard changes in working directory)\n","\n","\t\u001b[31mmodified:   test.sh\u001b[m\n","\n","no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GPLqh4RBnwv6","outputId":"965d02a9-7188-4a47-b2c5-41c41ab1ac97"},"source":["!chmod +x train.sh\n","!./train.sh"],"execution_count":null,"outputs":[{"output_type":"stream","text":["export CUDA_VISIBLE_DEVICES=0\n","Disabled distributed training.\n","Path already exists. Rename it to [/content/gdrive/MyDrive/vinAI/noise2self/experiments/BSD68_noise2void_archived_210105-163431]\n","21-01-05 16:34:31.789 - INFO:   name: BSD68_noise2void\n","  use_tb_logger: True\n","  trainer: noise2void\n","  scale: 1\n","  gpu_ids: [0]\n","  datasets:[\n","    train:[\n","      name: BSD68\n","      mode: BSD68\n","      interval_list: [1]\n","      HQ_data: None\n","      LQ_data: ../BSD68/train/noise.npy\n","      use_shuffle: True\n","      n_workers: 4\n","      batch_size: 64\n","      HQ_size: 64\n","      use_flip: True\n","      use_rot: True\n","      phase: train\n","      data_type: img\n","    ]\n","    val:[\n","      name: BSD68\n","      mode: BSD68\n","      interval_list: [1]\n","      HQ_data: ../BSD68/val/clean.npy\n","      LQ_data: ../BSD68/val/noise.npy\n","      use_shuffle: False\n","      n_workers: 4\n","      batch_size: 1\n","      phase: val\n","      data_type: img\n","    ]\n","  ]\n","  network_G:[\n","    img_channels: 1\n","  ]\n","  path:[\n","    pretrain_model_G: None\n","    strict_load: True\n","    resume_state: None\n","    root: /content/gdrive/MyDrive/vinAI/noise2self\n","    experiments_root: /content/gdrive/MyDrive/vinAI/noise2self/experiments/BSD68_noise2void\n","    models: /content/gdrive/MyDrive/vinAI/noise2self/experiments/BSD68_noise2void/models\n","    training_state: /content/gdrive/MyDrive/vinAI/noise2self/experiments/BSD68_noise2void/training_state\n","    log: /content/gdrive/MyDrive/vinAI/noise2self/experiments/BSD68_noise2void\n","    val_images: /content/gdrive/MyDrive/vinAI/noise2self/experiments/BSD68_noise2void/val_images\n","  ]\n","  train:[\n","    lr_G: 0.0004\n","    lr_scheme: CosineAnnealingLR_Restart\n","    beta1: 0.9\n","    beta2: 0.99\n","    niter: 150000\n","    warmup_iter: -1\n","    T_period: [50000, 100000, 150000, 150000, 150000]\n","    restarts: [50000, 150000, 300000, 450000]\n","    restart_weights: [1, 1, 1, 1]\n","    eta_min: 1e-06\n","    pixel_criterion: l2\n","    pixel_weight: 1.0\n","    val_freq: 5000.0\n","    manual_seed: 0\n","  ]\n","  logger:[\n","    print_freq: 500\n","    save_checkpoint_freq: 10000.0\n","  ]\n","  is_train: True\n","  dist: False\n","\n","2021-01-05 16:34:31.959419: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n","21-01-05 16:34:33.497 - INFO: Random seed: 0\n","21-01-05 16:34:33.630 - INFO: Dataset [BSD68Dataset - BSD68] is created.\n","21-01-05 16:34:33.631 - INFO: Number of train images: 400, iters: 7\n","21-01-05 16:34:33.631 - INFO: Total epochs needed: 21429 for iters 150,000\n","21-01-05 16:34:33.680 - INFO: Dataset [BSD68Dataset - BSD68] is created.\n","21-01-05 16:34:33.680 - INFO: Number of val images in [BSD68]: 12\n","21-01-05 16:34:38.884 - INFO: Network G structure: DataParallel - Unet,                         with parameters: 3,325,355\n","21-01-05 16:34:38.885 - INFO: Unet(\n","  (down1): Conv2d(32, 32, kernel_size=(2, 2), stride=(2, 2), groups=32)\n","  (down2): Conv2d(64, 64, kernel_size=(2, 2), stride=(2, 2), groups=64)\n","  (down3): Conv2d(128, 128, kernel_size=(2, 2), stride=(2, 2), groups=128)\n","  (down4): Conv2d(256, 256, kernel_size=(2, 2), stride=(2, 2), groups=256)\n","  (up1): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), groups=256)\n","  (up2): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2), groups=128)\n","  (up3): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2), groups=64)\n","  (up4): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2), groups=32)\n","  (conv1): ConvBlock(\n","    (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (actfun1): LeakyReLU(negative_slope=0.01)\n","    (actfun2): LeakyReLU(negative_slope=0.01)\n","  )\n","  (conv2): ConvBlock(\n","    (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (actfun1): LeakyReLU(negative_slope=0.01)\n","    (actfun2): LeakyReLU(negative_slope=0.01)\n","  )\n","  (conv3): ConvBlock(\n","    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (actfun1): LeakyReLU(negative_slope=0.01)\n","    (actfun2): LeakyReLU(negative_slope=0.01)\n","  )\n","  (conv4): ConvBlock(\n","    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (actfun1): LeakyReLU(negative_slope=0.01)\n","    (actfun2): LeakyReLU(negative_slope=0.01)\n","  )\n","  (conv5): ConvBlock(\n","    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (actfun1): LeakyReLU(negative_slope=0.01)\n","    (actfun2): LeakyReLU(negative_slope=0.01)\n","  )\n","  (conv6): ConvBlock(\n","    (conv1): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (actfun1): LeakyReLU(negative_slope=0.01)\n","    (actfun2): LeakyReLU(negative_slope=0.01)\n","  )\n","  (conv7): ConvBlock(\n","    (conv1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (actfun1): LeakyReLU(negative_slope=0.01)\n","    (actfun2): LeakyReLU(negative_slope=0.01)\n","  )\n","  (conv8): ConvBlock(\n","    (conv1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (actfun1): LeakyReLU(negative_slope=0.01)\n","    (actfun2): LeakyReLU(negative_slope=0.01)\n","  )\n","  (conv9): ConvBlock(\n","    (conv1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (actfun1): LeakyReLU(negative_slope=0.01)\n","    (actfun2): LeakyReLU(negative_slope=0.01)\n","  )\n",")\n","21-01-05 16:34:38.886 - INFO: Trainer [Noise2VoidTrainer] is created.\n","Model created!\n","21-01-05 16:34:38.886 - INFO: Start training from epoch: 0, iter: 0\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"],"name":"stdout"}]}]}